{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ls4a_USPOald"
   },
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\zachr\\miniconda3\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "x7MCMPm7OeKu"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xHTztbYGOg1b"
   },
   "source": [
    "#Data Collection\n",
    "Load the first CSV file containing years 2000-2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9xCWgzTsPF6_"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    df_spotify = pd.read_csv('billboard_24years_lyrics_spotify.csv', encoding='utf-8')\n",
    "except UnicodeDecodeError:\n",
    "    df_spotify = pd.read_csv('billboard_24years_lyrics_spotify.csv', encoding='latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zu0rFqJCSDWl"
   },
   "source": [
    "Load the second CSV file containing years 1964-2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "N9fzRpZCSDsH"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    df_1964_2015 = pd.read_csv('billboard_lyrics_1964-2015.csv', encoding='utf-8')\n",
    "except UnicodeDecodeError:\n",
    "    df_1964_2015 = pd.read_csv('billboard_lyrics_1964-2015.csv', encoding='latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ZynI2YnTZ0T"
   },
   "source": [
    "#Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DSqaVEJDPJ_S"
   },
   "source": [
    "Filter for years 2016 to 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "D-VjTYOhPKJd"
   },
   "outputs": [],
   "source": [
    "df_spotify_filtered = df_spotify[df_spotify['year'].between(2016, 2024)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BReRcbzmPSRc"
   },
   "source": [
    "Remove duplicate records based on all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "dTMl-vioQVQz"
   },
   "outputs": [],
   "source": [
    "df_spotify_filtered = df_spotify_filtered.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v31qzSClQcFi"
   },
   "source": [
    "Function to clean lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "xQQ_hUEJQbGn"
   },
   "outputs": [],
   "source": [
    "def clean_lyrics_ascii(text):\n",
    "    if pd.isna(text):  # Handle missing values\n",
    "        return ''\n",
    "    text = text.lower() # Convert to lowercase\n",
    "\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text) # Remove non-ASCII characters\n",
    "\n",
    "    text = re.sub(r'\\s*\\'\\s*', '', text) # Remove apostrophes and merge contractions\n",
    "\n",
    "    text = re.sub(r'[^a-z0-9\\s]', ' ', text) # Remove all punctuation except spaces, keep letters and numbers\n",
    "\n",
    "    text = re.sub(r'\\d+embed$', '', text) # Remove number followed by \"embed\" at the end\n",
    "\n",
    "    text = re.sub(r'\\s+', ' ', text).strip() # Replace multiple spaces with a single space and remove leading/trailing whitespace\n",
    "\n",
    "    return text\n",
    "\n",
    "df_spotify_filtered['lyrics_cleaned'] = df_spotify_filtered['lyrics'].apply(clean_lyrics_ascii)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7SfBhgKdRU50"
   },
   "source": [
    "Select and rename columns for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "TC3idw3CRVxQ"
   },
   "outputs": [],
   "source": [
    "df_spotify_cleaned = df_spotify_filtered[['song', 'band_singer', 'year', 'ranking', 'lyrics_cleaned']]\n",
    "\n",
    "df_spotify_cleaned = df_spotify_cleaned.rename(columns={\n",
    "    'band_singer': 'artist'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F4Cwhi7oS85r"
   },
   "source": [
    "Rename columns to match the first dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "DOLWBsW8S94O"
   },
   "outputs": [],
   "source": [
    "df_1964_2015 = df_1964_2015.rename(columns={\n",
    "    'Song': 'song',\n",
    "    'Artist': 'artist',\n",
    "    'Year': 'year',\n",
    "    'Rank': 'ranking',\n",
    "    'Lyrics': 'lyrics_cleaned'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-DnFr28TBz3"
   },
   "source": [
    "Select only the required columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "2B30YuytTCBh"
   },
   "outputs": [],
   "source": [
    "df_1964_2015_cleaned = df_1964_2015[['song', 'artist', 'year', 'ranking', 'lyrics_cleaned']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DEfcr1qZTj1Q"
   },
   "source": [
    "Combine the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ee96PwPRTkNl"
   },
   "outputs": [],
   "source": [
    "df_combined = pd.concat([df_1964_2015_cleaned, df_spotify_cleaned], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lvdp6KE7T-01"
   },
   "source": [
    "Remove duplicates across the combined dataset (based on all columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "B9gPml7mT_EX"
   },
   "outputs": [],
   "source": [
    "df_combined = df_combined.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uF3GhtMmU0u8"
   },
   "source": [
    "Inspect the first few rows of the combined DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O-f9ISgmU1BV",
    "outputId": "79bf8d8b-e0f5-4975-ce6c-31337d078e6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Cleaned DataFrame (First 5 rows):\n",
      "                                       song                         artist  \\\n",
      "0                               wooly bully  sam the sham and the pharaohs   \n",
      "1  i cant help myself sugar pie honey bunch                      four tops   \n",
      "2                i cant get no satisfaction             the rolling stones   \n",
      "3                       you were on my mind                        we five   \n",
      "4              youve lost that lovin feelin         the righteous brothers   \n",
      "\n",
      "   year  ranking                                     lyrics_cleaned  \n",
      "0  1965        1  sam the sham miscellaneous wooly bully wooly b...  \n",
      "1  1965        2   sugar pie honey bunch you know that i love yo...  \n",
      "2  1965        3                                                     \n",
      "3  1965        4   when i woke up this morning you were on my mi...  \n",
      "4  1965        5   you never close your eyes anymore when i kiss...  \n",
      "\n",
      "Original vs Cleaned Lyrics (First 5 rows from 2016-2024 data):\n",
      "Song: Love Yourself (Year: 2016, Rank: 1)\n",
      "Original: \n",
      "For all the times that you rained on my parade\n",
      "And all the clubs you get in using my name\n",
      "You think you broke my heart, oh girl, for goodness' sake\n",
      "You think I'm cryin' on my own, well, I ain't\n",
      "\n",
      "And I didn't wanna write a song\n",
      "'Cause I didn't want anyone thinking I still care\n",
      "I don't, but you still hit my phone up\n",
      "And baby, I'll be movin' on\n",
      "And I think you should be somethin' I don't wanna hold back\n",
      "Maybe you should know that\n",
      "\n",
      "My mama don't like you and she likes everyone\n",
      "And I never like to admit that I was wrong\n",
      "And I've been so caught up in my job, didn't see what's going on\n",
      "But now I know, I'm better sleeping on my own\n",
      "\n",
      "'Cause if you like the way you look that much\n",
      "Oh baby, you should go and love yourself\n",
      "And if you think that I'm still holdin' on to somethin'\n",
      "You should go and love yourself\n",
      "You might also like\n",
      "But when you told me that you hated my friends\n",
      "The only problem was with you and not them\n",
      "And every time you told me my opinion was wrong\n",
      "And tried to make me forget where I came from\n",
      "\n",
      "And I didn't wanna write a song\n",
      "'Cause I didn't want anyone thinking I still care\n",
      "I don't, but you still hit my phone up\n",
      "And baby, I'll be movin' on\n",
      "And I think you should be somethin' I don't wanna hold back\n",
      "Maybe you should know that\n",
      "\n",
      "My mama don't like you and she likes everyone\n",
      "And I never like to admit that I was wrong\n",
      "And I've been so caught up in my job, didn't see what's going on\n",
      "But now I know, I'm better sleeping on my own\n",
      "\n",
      "'Cause if you like the way you look that much\n",
      "Oh baby, you should go and love yourself\n",
      "And if you think that I'm still holdin' on to somethin'\n",
      "You should go and love yourself\n",
      "For all the times that you made me feel small\n",
      "I fell in love, now I feel nothin' at all\n",
      "I never felt so low and I was vulnerable\n",
      "Was I a fool to let you break down my walls?\n",
      "\n",
      "'Cause if you like the way you look that much\n",
      "Oh baby, you should go and love yourself\n",
      "And if you think that I'm still holdin' on to somethin'\n",
      "You should go and love yourself\n",
      "'Cause if you like the way you look that much\n",
      "Oh baby, you should go and love yourself\n",
      "And if you think that I'm still holdin' on to somethin'\n",
      "You should go and love yourself150Embed\n",
      "Cleaned: for all the times that you rained on my parade and all the clubs you get in using my name you think you broke my heart oh girl for goodnesssake you think im cryinon my own well i aint and i didnt wanna write a songcause i didnt want anyone thinking i still care i dont but you still hit my phone up and baby ill be movinon and i think you should be somethini dont wanna hold back maybe you should know that my mama dont like you and she likes everyone and i never like to admit that i was wrong and ive been so caught up in my job didnt see whats going on but now i know im better sleeping on my owncause if you like the way you look that much oh baby you should go and love yourself and if you think that im still holdinon to somethinyou should go and love yourself you might also like but when you told me that you hated my friends the only problem was with you and not them and every time you told me my opinion was wrong and tried to make me forget where i came from and i didnt wanna write a songcause i didnt want anyone thinking i still care i dont but you still hit my phone up and baby ill be movinon and i think you should be somethini dont wanna hold back maybe you should know that my mama dont like you and she likes everyone and i never like to admit that i was wrong and ive been so caught up in my job didnt see whats going on but now i know im better sleeping on my owncause if you like the way you look that much oh baby you should go and love yourself and if you think that im still holdinon to somethinyou should go and love yourself for all the times that you made me feel small i fell in love now i feel nothinat all i never felt so low and i was vulnerable was i a fool to let you break down my walls cause if you like the way you look that much oh baby you should go and love yourself and if you think that im still holdinon to somethinyou should go and love yourselfcause if you like the way you look that much oh baby you should go and love yourself and if you think that im still holdinon to somethinyou should go and love yourself\n",
      "--------------------------------------------------\n",
      "Song: Sorry (Year: 2016, Rank: 2)\n",
      "Original: \n",
      "You gotta go and get angry at all of my honesty\n",
      "You know I try, but I don't do too well with apologies\n",
      "I hope I don't run out of time, could someone call a referee?\n",
      "'Cause I just need one more shot at forgiveness\n",
      "I know you know that I made those mistakes maybe once or twice\n",
      "And by once or twice, I mean maybe a couple of hundred times\n",
      "So let me, oh, let me redeem, oh, redeem, oh, myself tonight\n",
      "'Cause I just need one more shot at second chances\n",
      "\n",
      "Yeah, is it too late now to say sorry?\n",
      "'Cause I'm missing more than just your body\n",
      "Oh, is it too late now to say sorry?\n",
      "Yeah, I know that I let you down\n",
      "Is it too late to say I'm sorry now?\n",
      "\n",
      "I'm sorry, yeah\n",
      "Sorry, yeah\n",
      "Sorry\n",
      "Yeah, I know that I let you down\n",
      "Is it too late to say I'm sorry now?\n",
      "You might also like\n",
      "I'll take every single piece of the blame if you want me to\n",
      "But you know that there is no innocent one in this game for two\n",
      "I'll go, I'll go and then you go, you go out and spill the truth\n",
      "Can we both say the words and forget this?\n",
      "\n",
      "Yeah, is it too late now to say sorry?\n",
      "'Cause I'm missing more than just your body\n",
      "Oh, is it too late now to say sorry?\n",
      "Yeah, I know that I let you down\n",
      "Is it too late to say I'm sorry now?\n",
      "I'm not just tryna get you back on me (Oh, no, no)\n",
      "'Cause I'm missing more than just your body (Your body)\n",
      "Oh, is it too late now to say sorry?\n",
      "Yeah, I know that I let you down\n",
      "Is it too late to say I'm sorry now?\n",
      "\n",
      "I'm sorry, yeah\n",
      "Sorry, oh\n",
      "Sorry\n",
      "Yeah, I know that I let you down (I know I let you down)\n",
      "Is it too late to say I'm sorry now?\n",
      "I'm sorry, yeah\n",
      "Sorry, oh\n",
      "Sorry\n",
      "Yeah, I know that I let you down (I know I let you down)\n",
      "Is it too late to say I'm sorry now?101Embed\n",
      "Cleaned: you gotta go and get angry at all of my honesty you know i try but i dont do too well with apologies i hope i dont run out of time could someone call a referee cause i just need one more shot at forgiveness i know you know that i made those mistakes maybe once or twice and by once or twice i mean maybe a couple of hundred times so let me oh let me redeem oh redeem oh myself tonightcause i just need one more shot at second chances yeah is it too late now to say sorry cause im missing more than just your body oh is it too late now to say sorry yeah i know that i let you down is it too late to say im sorry now im sorry yeah sorry yeah sorry yeah i know that i let you down is it too late to say im sorry now you might also like ill take every single piece of the blame if you want me to but you know that there is no innocent one in this game for two ill go ill go and then you go you go out and spill the truth can we both say the words and forget this yeah is it too late now to say sorry cause im missing more than just your body oh is it too late now to say sorry yeah i know that i let you down is it too late to say im sorry now im not just tryna get you back on me oh no no cause im missing more than just your body your body oh is it too late now to say sorry yeah i know that i let you down is it too late to say im sorry now im sorry yeah sorry oh sorry yeah i know that i let you down i know i let you down is it too late to say im sorry now im sorry yeah sorry oh sorry yeah i know that i let you down i know i let you down is it too late to say im sorry now\n",
      "--------------------------------------------------\n",
      "Song: One Dance (Year: 2016, Rank: 3)\n",
      "Original: Baby, I like your style\n",
      "\n",
      "Grips on your waist, front way, back way\n",
      "You know that I don't play\n",
      "Streets not safe but I never run away\n",
      "Even when I'm away\n",
      "Oti, oti\n",
      "There's never much love when we go OT\n",
      "I pray to make it back in one piece\n",
      "I pray, I pray\n",
      "\n",
      "That's why I need a one dance\n",
      "Got a Hennessy in my hand\n",
      "One more time 'fore I go\n",
      "Higher powers taking a hold on me\n",
      "I need a one dance\n",
      "Got a Hennessy in my hand\n",
      "One more time 'fore I go\n",
      "Higher powers taking a hold on me\n",
      "Baby, I like your style\n",
      "You might also like\n",
      "Strength and guidance\n",
      "All that I'm wishing for my friends\n",
      "Nobody makes it from my ends\n",
      "I had to bust up the silence\n",
      "You know you gotta stick by me\n",
      "Soon as you see the text, reply me\n",
      "I don't wanna spend time fighting\n",
      "We've got no time, and that's why\n",
      "\n",
      "I need a one dance\n",
      "Got a Hennessy in my hand\n",
      "One more time 'fore I go\n",
      "Higher powers taking a hold on me\n",
      "I need a one dance\n",
      "Got a Hennessy in my hand\n",
      "One more time 'fore I go\n",
      "Higher powers taking a hold on me\n",
      "\n",
      "Got a pretty girl and she love me long time\n",
      "Wine it, wine it, she love me long time\n",
      "Oh, yeah, very long time\n",
      "Back up, back up, back up, and wine am\n",
      "Back up, back up, and wine am, girl, just\n",
      "Back up, back up, back up, and wine am\n",
      "Oh, yeah, very long time\n",
      "Back, up, back up and wine am, girl\n",
      "Oh, tell me, I need to know\n",
      "Where do you wanna go?\n",
      "'Cause if you're down, I'll take it slow\n",
      "Make you lose control\n",
      "\n",
      "Where, where, where\n",
      "Where, where, where, where (Oh, yeah, very long time)\n",
      "Where, where, where (Back up, back up, and wine am, girl)\n",
      "Where, where, where, where\n",
      "'Cause if you're down (Back up, back up, and–)\n",
      "'Cause if you're down (Back up, back up, and–)\n",
      "'Cause if you're down (Back up, back up, and–)\n",
      "\n",
      "I need a one dance (Where, where, where)\n",
      "Got a Hennessy in my hand (Where, where, where, where)\n",
      "One more time 'fore I go (Where)\n",
      "Higher powers taking a hold on me (Where, where, where, where)\n",
      "I need a one dance\n",
      "Got a Hennessy in my hand\n",
      "One more time 'fore I go\n",
      "Higher powers taking a hold on me\n",
      "How do you spell \"Hennessy?\"\n",
      "I put two \"N\"s and two \"S\"es, is it like that? Hen... Henn... Henn...\n",
      "It's definitely not showing up\n",
      "I know \"Hennessy\" has two \"S\"es for sure, so I'm gonna take out one of the \"N\"s234Embed\n",
      "Cleaned: baby i like your style grips on your waist front way back way you know that i dont play streets not safe but i never run away even when im away oti oti theres never much love when we go ot i pray to make it back in one piece i pray i pray thats why i need a one dance got a hennessy in my hand one more timefore i go higher powers taking a hold on me i need a one dance got a hennessy in my hand one more timefore i go higher powers taking a hold on me baby i like your style you might also like strength and guidance all that im wishing for my friends nobody makes it from my ends i had to bust up the silence you know you gotta stick by me soon as you see the text reply me i dont wanna spend time fighting weve got no time and thats why i need a one dance got a hennessy in my hand one more timefore i go higher powers taking a hold on me i need a one dance got a hennessy in my hand one more timefore i go higher powers taking a hold on me got a pretty girl and she love me long time wine it wine it she love me long time oh yeah very long time back up back up back up and wine am back up back up and wine am girl just back up back up back up and wine am oh yeah very long time back up back up and wine am girl oh tell me i need to know where do you wanna go cause if youre down ill take it slow make you lose control where where where where where where where oh yeah very long time where where where back up back up and wine am girl where where where wherecause if youre down back up back up and cause if youre down back up back up and cause if youre down back up back up and i need a one dance where where where got a hennessy in my hand where where where where one more timefore i go where higher powers taking a hold on me where where where where i need a one dance got a hennessy in my hand one more timefore i go higher powers taking a hold on me how do you spell hennessy i put two n s and two s es is it like that hen henn henn its definitely not showing up i know hennessy has two s es for sure so im gonna take out one of the n s\n",
      "--------------------------------------------------\n",
      "Song: One Dance (Year: 2016, Rank: 3)\n",
      "Original: Baby, I like your style\n",
      "\n",
      "Grips on your waist, front way, back way\n",
      "You know that I don't play\n",
      "Streets not safe but I never run away\n",
      "Even when I'm away\n",
      "Oti, oti\n",
      "There's never much love when we go OT\n",
      "I pray to make it back in one piece\n",
      "I pray, I pray\n",
      "\n",
      "That's why I need a one dance\n",
      "Got a Hennessy in my hand\n",
      "One more time 'fore I go\n",
      "Higher powers taking a hold on me\n",
      "I need a one dance\n",
      "Got a Hennessy in my hand\n",
      "One more time 'fore I go\n",
      "Higher powers taking a hold on me\n",
      "Baby, I like your style\n",
      "You might also like\n",
      "Strength and guidance\n",
      "All that I'm wishing for my friends\n",
      "Nobody makes it from my ends\n",
      "I had to bust up the silence\n",
      "You know you gotta stick by me\n",
      "Soon as you see the text, reply me\n",
      "I don't wanna spend time fighting\n",
      "We've got no time, and that's why\n",
      "\n",
      "I need a one dance\n",
      "Got a Hennessy in my hand\n",
      "One more time 'fore I go\n",
      "Higher powers taking a hold on me\n",
      "I need a one dance\n",
      "Got a Hennessy in my hand\n",
      "One more time 'fore I go\n",
      "Higher powers taking a hold on me\n",
      "\n",
      "Got a pretty girl and she love me long time\n",
      "Wine it, wine it, she love me long time\n",
      "Oh, yeah, very long time\n",
      "Back up, back up, back up, and wine am\n",
      "Back up, back up, and wine am, girl, just\n",
      "Back up, back up, back up, and wine am\n",
      "Oh, yeah, very long time\n",
      "Back, up, back up and wine am, girl\n",
      "Oh, tell me, I need to know\n",
      "Where do you wanna go?\n",
      "'Cause if you're down, I'll take it slow\n",
      "Make you lose control\n",
      "\n",
      "Where, where, where\n",
      "Where, where, where, where (Oh, yeah, very long time)\n",
      "Where, where, where (Back up, back up, and wine am, girl)\n",
      "Where, where, where, where\n",
      "'Cause if you're down (Back up, back up, and–)\n",
      "'Cause if you're down (Back up, back up, and–)\n",
      "'Cause if you're down (Back up, back up, and–)\n",
      "\n",
      "I need a one dance (Where, where, where)\n",
      "Got a Hennessy in my hand (Where, where, where, where)\n",
      "One more time 'fore I go (Where)\n",
      "Higher powers taking a hold on me (Where, where, where, where)\n",
      "I need a one dance\n",
      "Got a Hennessy in my hand\n",
      "One more time 'fore I go\n",
      "Higher powers taking a hold on me\n",
      "How do you spell \"Hennessy?\"\n",
      "I put two \"N\"s and two \"S\"es, is it like that? Hen... Henn... Henn...\n",
      "It's definitely not showing up\n",
      "I know \"Hennessy\" has two \"S\"es for sure, so I'm gonna take out one of the \"N\"s234Embed\n",
      "Cleaned: baby i like your style grips on your waist front way back way you know that i dont play streets not safe but i never run away even when im away oti oti theres never much love when we go ot i pray to make it back in one piece i pray i pray thats why i need a one dance got a hennessy in my hand one more timefore i go higher powers taking a hold on me i need a one dance got a hennessy in my hand one more timefore i go higher powers taking a hold on me baby i like your style you might also like strength and guidance all that im wishing for my friends nobody makes it from my ends i had to bust up the silence you know you gotta stick by me soon as you see the text reply me i dont wanna spend time fighting weve got no time and thats why i need a one dance got a hennessy in my hand one more timefore i go higher powers taking a hold on me i need a one dance got a hennessy in my hand one more timefore i go higher powers taking a hold on me got a pretty girl and she love me long time wine it wine it she love me long time oh yeah very long time back up back up back up and wine am back up back up and wine am girl just back up back up back up and wine am oh yeah very long time back up back up and wine am girl oh tell me i need to know where do you wanna go cause if youre down ill take it slow make you lose control where where where where where where where oh yeah very long time where where where back up back up and wine am girl where where where wherecause if youre down back up back up and cause if youre down back up back up and cause if youre down back up back up and i need a one dance where where where got a hennessy in my hand where where where where one more timefore i go where higher powers taking a hold on me where where where where i need a one dance got a hennessy in my hand one more timefore i go higher powers taking a hold on me how do you spell hennessy i put two n s and two s es is it like that hen henn henn its definitely not showing up i know hennessy has two s es for sure so im gonna take out one of the n s\n",
      "--------------------------------------------------\n",
      "Song: One Dance (Year: 2016, Rank: 3)\n",
      "Original: Baby, I like your style\n",
      "\n",
      "Grips on your waist, front way, back way\n",
      "You know that I don't play\n",
      "Streets not safe but I never run away\n",
      "Even when I'm away\n",
      "Oti, oti\n",
      "There's never much love when we go OT\n",
      "I pray to make it back in one piece\n",
      "I pray, I pray\n",
      "\n",
      "That's why I need a one dance\n",
      "Got a Hennessy in my hand\n",
      "One more time 'fore I go\n",
      "Higher powers taking a hold on me\n",
      "I need a one dance\n",
      "Got a Hennessy in my hand\n",
      "One more time 'fore I go\n",
      "Higher powers taking a hold on me\n",
      "Baby, I like your style\n",
      "You might also like\n",
      "Strength and guidance\n",
      "All that I'm wishing for my friends\n",
      "Nobody makes it from my ends\n",
      "I had to bust up the silence\n",
      "You know you gotta stick by me\n",
      "Soon as you see the text, reply me\n",
      "I don't wanna spend time fighting\n",
      "We've got no time, and that's why\n",
      "\n",
      "I need a one dance\n",
      "Got a Hennessy in my hand\n",
      "One more time 'fore I go\n",
      "Higher powers taking a hold on me\n",
      "I need a one dance\n",
      "Got a Hennessy in my hand\n",
      "One more time 'fore I go\n",
      "Higher powers taking a hold on me\n",
      "\n",
      "Got a pretty girl and she love me long time\n",
      "Wine it, wine it, she love me long time\n",
      "Oh, yeah, very long time\n",
      "Back up, back up, back up, and wine am\n",
      "Back up, back up, and wine am, girl, just\n",
      "Back up, back up, back up, and wine am\n",
      "Oh, yeah, very long time\n",
      "Back, up, back up and wine am, girl\n",
      "Oh, tell me, I need to know\n",
      "Where do you wanna go?\n",
      "'Cause if you're down, I'll take it slow\n",
      "Make you lose control\n",
      "\n",
      "Where, where, where\n",
      "Where, where, where, where (Oh, yeah, very long time)\n",
      "Where, where, where (Back up, back up, and wine am, girl)\n",
      "Where, where, where, where\n",
      "'Cause if you're down (Back up, back up, and–)\n",
      "'Cause if you're down (Back up, back up, and–)\n",
      "'Cause if you're down (Back up, back up, and–)\n",
      "\n",
      "I need a one dance (Where, where, where)\n",
      "Got a Hennessy in my hand (Where, where, where, where)\n",
      "One more time 'fore I go (Where)\n",
      "Higher powers taking a hold on me (Where, where, where, where)\n",
      "I need a one dance\n",
      "Got a Hennessy in my hand\n",
      "One more time 'fore I go\n",
      "Higher powers taking a hold on me\n",
      "How do you spell \"Hennessy?\"\n",
      "I put two \"N\"s and two \"S\"es, is it like that? Hen... Henn... Henn...\n",
      "It's definitely not showing up\n",
      "I know \"Hennessy\" has two \"S\"es for sure, so I'm gonna take out one of the \"N\"s234Embed\n",
      "Cleaned: baby i like your style grips on your waist front way back way you know that i dont play streets not safe but i never run away even when im away oti oti theres never much love when we go ot i pray to make it back in one piece i pray i pray thats why i need a one dance got a hennessy in my hand one more timefore i go higher powers taking a hold on me i need a one dance got a hennessy in my hand one more timefore i go higher powers taking a hold on me baby i like your style you might also like strength and guidance all that im wishing for my friends nobody makes it from my ends i had to bust up the silence you know you gotta stick by me soon as you see the text reply me i dont wanna spend time fighting weve got no time and thats why i need a one dance got a hennessy in my hand one more timefore i go higher powers taking a hold on me i need a one dance got a hennessy in my hand one more timefore i go higher powers taking a hold on me got a pretty girl and she love me long time wine it wine it she love me long time oh yeah very long time back up back up back up and wine am back up back up and wine am girl just back up back up back up and wine am oh yeah very long time back up back up and wine am girl oh tell me i need to know where do you wanna go cause if youre down ill take it slow make you lose control where where where where where where where oh yeah very long time where where where back up back up and wine am girl where where where wherecause if youre down back up back up and cause if youre down back up back up and cause if youre down back up back up and i need a one dance where where where got a hennessy in my hand where where where where one more timefore i go where higher powers taking a hold on me where where where where i need a one dance got a hennessy in my hand one more timefore i go higher powers taking a hold on me how do you spell hennessy i put two n s and two s es is it like that hen henn henn its definitely not showing up i know hennessy has two s es for sure so im gonna take out one of the n s\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Combined Cleaned DataFrame (First 5 rows):\")\n",
    "print(df_combined.head())\n",
    "print(\"\\nOriginal vs Cleaned Lyrics (First 5 rows from 2016-2024 data):\")\n",
    "for i in range(min(5, len(df_spotify_filtered))):\n",
    "    print(f\"Song: {df_spotify_filtered['song'].iloc[i]} (Year: {df_spotify_filtered['year'].iloc[i]}, Rank: {df_spotify_filtered['ranking'].iloc[i]})\")\n",
    "    print(f\"Original: {df_spotify_filtered['lyrics'].iloc[i]}\")\n",
    "    print(f\"Cleaned: {df_spotify_filtered['lyrics_cleaned'].iloc[i]}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-DuHoigU5YN"
   },
   "source": [
    "Save the combined cleaned data to a new CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pl7z-1IaU5wp",
    "outputId": "c1552d0c-eae4-497d-9f42-4a6f4d479ebf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined cleaned data saved to 'billboard_1964_2024_lyrics_cleaned.csv'\n",
      "Number of unique records: 6280\n"
     ]
    }
   ],
   "source": [
    "df_combined.to_csv('billboard_1964_2024_lyrics_cleaned.csv', index=False)\n",
    "print(\"Combined cleaned data saved to 'billboard_1964_2024_lyrics_cleaned.csv'\")\n",
    "print(f\"Number of unique records: {len(df_combined)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CSxrq-gLgUKQ"
   },
   "source": [
    "Generating a basic score for judging a song's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wsIPkPF_gTc2",
    "outputId": "9a528c06-d559-4533-f6bc-6083fde685ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results to song_mycs_scores.csv\n",
      "\n",
      "Top 5 Songs by MYCS:\n",
      "                                 song         artist  \\\n",
      "156                   Blinding Lights     The Weeknd   \n",
      "2788                    how do i live    leann rimes   \n",
      "861                              Stay  Justin Bieber   \n",
      "862                              Stay  The Kid Laroi   \n",
      "71    All I Want for Christmas Is You   Mariah Carey   \n",
      "\n",
      "                          year           ranking   MYCS  \n",
      "156               [2020, 2021]            [1, 3]  2.376  \n",
      "2788              [1997, 1998]            [9, 5]  2.256  \n",
      "861               [2021, 2022]           [12, 3]  2.244  \n",
      "862               [2021, 2022]           [12, 3]  2.244  \n",
      "71    [2020, 2021, 2022, 2023]  [67, 78, 65, 55]  2.224  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('billboard_1964_2024_lyrics_cleaned.csv')\n",
    "\n",
    "# Group by song, artist, and year to ensure uniqueness\n",
    "grouped = df.groupby(['song', 'artist']).agg({\n",
    "    'ranking': list,   # List of rankings across years\n",
    "    'year': list,      # List of years charted\n",
    "    'lyrics_cleaned': 'first'  # Keep first instance of lyrics\n",
    "}).reset_index()\n",
    "\n",
    "\n",
    "def calculate_mycs(rankings, alpha=0.2):\n",
    "    \"\"\"\n",
    "    Compute Multi-Year Chart Score for a song.\n",
    "\n",
    "    Args:\n",
    "        rankings (list): List of rankings (1-100) across years\n",
    "        alpha (float): Longevity weight (default: 0.2)\n",
    "\n",
    "    Returns:\n",
    "        float: MYCS score\n",
    "    \"\"\"\n",
    "    # Yearly rank scores: (101 - rank)/100\n",
    "    yearly_scores = [(101 - rank)/100 for rank in rankings]\n",
    "    total_rank_score = sum(yearly_scores)\n",
    "\n",
    "    # Longevity multiplier\n",
    "    years = len(rankings)\n",
    "    longevity_multiplier = 1 + alpha * (years - 1)\n",
    "\n",
    "    return total_rank_score * longevity_multiplier\n",
    "\n",
    "grouped['MYCS'] = grouped['ranking'].apply(\n",
    "    lambda x: calculate_mycs(x, alpha=0.2)\n",
    ")\n",
    "\n",
    "grouped = grouped.sort_values('MYCS', ascending=False)\n",
    "\n",
    "\n",
    "output = grouped[['song', 'artist', 'year', 'ranking', 'MYCS', 'lyrics_cleaned']]\n",
    "\n",
    "# Save to CSV\n",
    "output.to_csv('song_mycs_scores.csv', index=False)\n",
    "print(\"Saved results to song_mycs_scores.csv\")\n",
    "\n",
    "\n",
    "print(\"\\nTop 5 Songs by MYCS:\")\n",
    "print(output.head(5)[['song', 'artist', 'year', 'ranking', 'MYCS']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9tWW1ZHFa9-o"
   },
   "source": [
    "A. Basic Statistical Features\n",
    "Length of lyrics (word count, character count)\n",
    "\n",
    "Unique word count (lexical richness)\n",
    "\n",
    "Average word length\n",
    "\n",
    "Stopword ratio (percentage of common words like \"the\", \"and\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dg9Wx1MZa9-o",
    "outputId": "b64a3d03-3da3-4511-d760-798a2059011c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              song  word_count  char_count   MYCS\n",
      "0                  Blinding Lights         261        1174  2.376\n",
      "1                    how do i live         279        1212  2.256\n",
      "2                             Stay         423        1790  2.244\n",
      "3                             Stay         423        1790  2.244\n",
      "4  All I Want for Christmas Is You         391        1843  2.224\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the MYCS file\n",
    "df_mycs = pd.read_csv('song_mycs_scores.csv')\n",
    "\n",
    "df_mycs['lyrics_cleaned'] = df_mycs['lyrics_cleaned'].astype(str)\n",
    "\n",
    "df_mycs['word_count'] = df_mycs['lyrics_cleaned'].apply(lambda x: len(x.split()))\n",
    "df_mycs['char_count'] = df_mycs['lyrics_cleaned'].apply(len)\n",
    "\n",
    "print(df_mycs[['song', 'word_count', 'char_count', 'MYCS']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "I7FvXeIxa9-o"
   },
   "outputs": [],
   "source": [
    "#Unique word count (lexical richness)\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L9h7fPdda9-o",
    "outputId": "7551c086-4bfd-4653-f54f-3f77a0a0b783"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              song  unique_word_count  distinct_word_count  \\\n",
      "0                  Blinding Lights                 43                   96   \n",
      "1                    how do i live                 27                   66   \n",
      "2                             Stay                 42                   88   \n",
      "3                             Stay                 42                   88   \n",
      "4  All I Want for Christmas Is You                 61                  113   \n",
      "\n",
      "   word_count   MYCS  \n",
      "0         261  2.376  \n",
      "1         279  2.256  \n",
      "2         423  2.244  \n",
      "3         423  2.244  \n",
      "4         391  2.224  \n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Unique word count: words that appear only once\n",
    "df_mycs['unique_word_count'] = df_mycs['lyrics_cleaned'].apply(\n",
    "    lambda x: sum(1 for count in Counter(x.split()).values() if count == 1)\n",
    ")\n",
    "\n",
    "# Optional: Store the actual unique words\n",
    "df_mycs['unique_words'] = df_mycs['lyrics_cleaned'].apply(\n",
    "    lambda x: [word for word, count in Counter(x.split()).items() if count == 1]\n",
    ")\n",
    "\n",
    "# Distinct word count: total number of different words used (vocabulary size)\n",
    "df_mycs['distinct_word_count'] = df_mycs['lyrics_cleaned'].apply(\n",
    "    lambda x: len(set(x.split()))\n",
    ")\n",
    "\n",
    "# Preview the updated DataFrame\n",
    "print(df_mycs[['song', 'unique_word_count', 'distinct_word_count', 'word_count', 'MYCS']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iEREODyfa9-o",
    "outputId": "44e9f8a6-b6fb-4c47-f7fb-f16964459282"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zachr\\miniconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\zachr\\miniconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              song  avg_word_length\n",
      "0                  Blinding Lights         3.501916\n",
      "1                    how do i live         3.340502\n",
      "2                             Stay         3.234043\n",
      "3                             Stay         3.234043\n",
      "4  All I Want for Christmas Is You         3.716113\n",
      "5                           Closer         3.985994\n",
      "6                       Heat Waves         4.190955\n",
      "7                        As It Was         3.529167\n",
      "8                           Closer         3.985994\n",
      "9                           smooth         3.788856\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# Calculate average word length\n",
    "df_mycs['avg_word_length'] = df_mycs['lyrics_cleaned'].apply(\n",
    "    lambda x: np.mean([len(word) for word in x.split()]) if x else 0\n",
    ")\n",
    "\n",
    "# Preview the result\n",
    "print(df_mycs[['song', 'avg_word_length']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\zachr\\miniconda3\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WH610MJra9-o",
    "outputId": "ce70e46f-fb4a-4e90-df2b-6ea1f93ff616"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\zachr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              song  stopword_ratio\n",
      "0                  Blinding Lights            0.43\n",
      "1                    how do i live            0.56\n",
      "2                             Stay            0.47\n",
      "3                             Stay            0.47\n",
      "4  All I Want for Christmas Is You            0.48\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "\n",
    "# Download stopwords if not already downloaded\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Calculate stopword ratio for df_mycs\n",
    "df_mycs['stopword_ratio'] = df_mycs['lyrics_cleaned'].apply(\n",
    "    lambda x: np.round(\n",
    "        sum(1 for word in str(x).split() if word.lower() in stop_words) / max(len(str(x).split()), 1),\n",
    "        2  # Round to 2 decimal places\n",
    "    )\n",
    ")\n",
    "\n",
    "# Preview result\n",
    "print(df_mycs[['song', 'stopword_ratio']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AOmI-uOAa9-p"
   },
   "source": [
    "B. Linguistic & Sentiment Features\n",
    "Sentiment Analysis (positive/negative sentiment score)\n",
    "\n",
    "Emotion detection (anger, joy, sadness, etc.)\n",
    "\n",
    "Lexical diversity (ratio of unique words to total words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TU0czZGOa9-p",
    "outputId": "da4c8655-0b3d-4a63-b82a-6e7263adb299"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\zachr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      lyrics_cleaned  pos_ratio  neg_ratio  \\\n",
      "0  yeah ive been tryna call ive been on my own fo...      0.077      0.094   \n",
      "1   how do i get through one night without you if...      0.039      0.071   \n",
      "2  i do the same thing i told you that i never wo...      0.071      0.095   \n",
      "3  i do the same thing i told you that i never wo...      0.071      0.095   \n",
      "4  i dont want a lot for christmas there is just ...      0.103      0.086   \n",
      "\n",
      "   neu_ratio  \n",
      "0      0.829  \n",
      "1      0.890  \n",
      "2      0.834  \n",
      "3      0.834  \n",
      "4      0.811  \n"
     ]
    }
   ],
   "source": [
    "#Sentiment Analysis (positive/negative sentiment score)\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "#Sentiment Analysis (positive/negative sentiment score)\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Initialize the sentiment analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to calculate sentiment ratios\n",
    "def sentiment_ratios(text):\n",
    "    scores = sia.polarity_scores(str(text))  # Get sentiment scores\n",
    "    total = scores['pos'] + scores['neg'] + scores['neu']  # Total sentiment score sum\n",
    "\n",
    "    if total == 0:  # Avoid division by zero\n",
    "        return (0, 0)\n",
    "\n",
    "    pos_ratio = scores['pos'] / total  # Positive sentiment ratio\n",
    "    neg_ratio = scores['neg'] / total  # Negative sentiment ratio\n",
    "    neu_ratio = scores ['neu'] / total\n",
    "    return pos_ratio, neg_ratio ,neu_ratio\n",
    "\n",
    "# Apply function to each row\n",
    "df_mycs[['pos_ratio', 'neg_ratio','neu_ratio']] = df_mycs['lyrics_cleaned'].apply(\n",
    "    lambda x: pd.Series(sentiment_ratios(x))\n",
    ")\n",
    "\n",
    "print(df_mycs[['lyrics_cleaned', 'pos_ratio', 'neg_ratio', 'neu_ratio']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MInNPiiV8ij1",
    "outputId": "5bb07a49-699a-4771-86b5-d86fd68e5947"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      lyrics_cleaned  compound\n",
      "0  yeah ive been tryna call ive been on my own fo...   -0.1068\n",
      "1   how do i get through one night without you if...   -0.1195\n",
      "2  i do the same thing i told you that i never wo...   -0.8523\n",
      "3  i do the same thing i told you that i never wo...   -0.8523\n",
      "4  i dont want a lot for christmas there is just ...    0.9672\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "df_mycs['compound'] = df_mycs['lyrics_cleaned'].apply(\n",
    "    lambda x: sia.polarity_scores(str(x))['compound']\n",
    ")\n",
    "print(df_mycs[['lyrics_cleaned', 'compound']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lexical Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              song  unique_word_count  word_count  \\\n",
      "0                  Blinding Lights                 43         261   \n",
      "1                    how do i live                 27         279   \n",
      "2                             Stay                 42         423   \n",
      "3                             Stay                 42         423   \n",
      "4  All I Want for Christmas Is You                 61         391   \n",
      "\n",
      "   lexical_diversity  \n",
      "0           0.164751  \n",
      "1           0.096774  \n",
      "2           0.099291  \n",
      "3           0.099291  \n",
      "4           0.156010  \n"
     ]
    }
   ],
   "source": [
    "# Lexical diversity: ratio of unique words (used only once) to total words\n",
    "df_mycs['lexical_diversity'] = df_mycs.apply(\n",
    "    lambda row: row['unique_word_count'] / row['word_count'] if row['word_count'] > 0 else 0,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Preview result\n",
    "print(df_mycs[['song', 'unique_word_count', 'word_count', 'lexical_diversity']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NiTedx_k8fDF"
   },
   "source": [
    "Syllable count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TJQnWKQqISx2",
    "outputId": "8bc7c416-f32d-4343-c6b5-655147c18928"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: phonemizer in c:\\users\\zachr\\miniconda3\\lib\\site-packages (3.3.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from phonemizer) (1.4.2)\n",
      "Requirement already satisfied: segments in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from phonemizer) (2.3.0)\n",
      "Requirement already satisfied: attrs>=18.1 in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from phonemizer) (25.3.0)\n",
      "Requirement already satisfied: dlinfo in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from phonemizer) (2.0.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from phonemizer) (4.12.2)\n",
      "Requirement already satisfied: regex in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from segments->phonemizer) (2024.11.6)\n",
      "Requirement already satisfied: csvw>=1.5.6 in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from segments->phonemizer) (3.5.1)\n",
      "Requirement already satisfied: isodate in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from csvw>=1.5.6->segments->phonemizer) (0.7.2)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from csvw>=1.5.6->segments->phonemizer) (2.9.0.post0)\n",
      "Requirement already satisfied: rfc3986<2 in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from csvw>=1.5.6->segments->phonemizer) (1.5.0)\n",
      "Requirement already satisfied: uritemplate>=3.0.0 in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from csvw>=1.5.6->segments->phonemizer) (4.1.1)\n",
      "Requirement already satisfied: babel in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from csvw>=1.5.6->segments->phonemizer) (2.17.0)\n",
      "Requirement already satisfied: requests in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from csvw>=1.5.6->segments->phonemizer) (2.32.3)\n",
      "Requirement already satisfied: language-tags in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from csvw>=1.5.6->segments->phonemizer) (1.2.0)\n",
      "Requirement already satisfied: rdflib in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from csvw>=1.5.6->segments->phonemizer) (7.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from csvw>=1.5.6->segments->phonemizer) (0.4.6)\n",
      "Requirement already satisfied: jsonschema in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from csvw>=1.5.6->segments->phonemizer) (4.23.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from jsonschema->csvw>=1.5.6->segments->phonemizer) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from jsonschema->csvw>=1.5.6->segments->phonemizer) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from jsonschema->csvw>=1.5.6->segments->phonemizer) (0.24.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from python-dateutil->csvw>=1.5.6->segments->phonemizer) (1.17.0)\n",
      "Requirement already satisfied: pyparsing<4,>=2.1.0 in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from rdflib->csvw>=1.5.6->segments->phonemizer) (3.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from requests->csvw>=1.5.6->segments->phonemizer) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from requests->csvw>=1.5.6->segments->phonemizer) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from requests->csvw>=1.5.6->segments->phonemizer) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from requests->csvw>=1.5.6->segments->phonemizer) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "!pip install phonemizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6uWVTfYGILSf",
    "outputId": "b66765d1-a637-4a3e-9fba-8b093e8df94b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: syllapy in c:\\users\\zachr\\miniconda3\\lib\\site-packages (0.7.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install syllapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xKzbuQc3IOwS",
    "outputId": "2f6240c8-4633-4723-8174-411ca7d578e7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement espeak-ng (from versions: none)\n",
      "ERROR: No matching distribution found for espeak-ng\n"
     ]
    }
   ],
   "source": [
    "!pip install espeak-ng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0usrxc8R9LOO",
    "outputId": "498465f2-6c26-4266-c1ea-822043a22cbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              song  syllable_count\n",
      "0                  Blinding Lights             299\n",
      "1                    how do i live             335\n",
      "2                             Stay             467\n",
      "3                             Stay             467\n",
      "4  All I Want for Christmas Is You             473\n"
     ]
    }
   ],
   "source": [
    "import syllapy\n",
    "\n",
    "# Function to count syllables in a text\n",
    "def count_syllables(text):\n",
    "    # Split text into words, count syllables for each word, and sum them\n",
    "    return sum(syllapy.count(word) for word in text.split())\n",
    "\n",
    "# Ensure 'lyrics_cleaned' is treated as a string\n",
    "df_mycs['lyrics_cleaned'] = df_mycs['lyrics_cleaned'].astype(str)\n",
    "\n",
    "# Calculate syllable count\n",
    "df_mycs['syllable_count'] = df_mycs['lyrics_cleaned'].apply(count_syllables)\n",
    "\n",
    "# Preview result\n",
    "print(df_mycs[['song', 'syllable_count']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Db1ds-AMudL",
    "outputId": "8fce54e5-c10a-413f-e24a-5269f7a45c90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pronouncing in c:\\users\\zachr\\miniconda3\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: cmudict>=0.4.0 in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from pronouncing) (1.0.32)\n",
      "Requirement already satisfied: importlib-metadata>=5 in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from cmudict>=0.4.0->pronouncing) (8.6.1)\n",
      "Requirement already satisfied: importlib-resources>=5 in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from cmudict>=0.4.0->pronouncing) (6.5.2)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from importlib-metadata>=5->cmudict>=0.4.0->pronouncing) (3.21.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pronouncing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eHIG9BR9vaLb",
    "outputId": "a45d9f3a-9054-4c81-aa1b-843ea3adb4cf"
   },
   "outputs": [],
   "source": [
    "import pronouncing\n",
    "\n",
    "\n",
    "def rhyme_count(lyrics):\n",
    "    words = str(lyrics).lower().split()\n",
    "    if not words or lyrics is None or pd.isna(lyrics):\n",
    "        return 0\n",
    "\n",
    "    # Get unique words to avoid overcounting repeats\n",
    "    unique_words = set(words)\n",
    "    rhyme_pairs = 0\n",
    "\n",
    "    # Check each word against others for rhymes\n",
    "    for i, word1 in enumerate(sorted(unique_words)):\n",
    "        rhymes = pronouncing.rhymes(word1)\n",
    "        for word2 in sorted(unique_words)[i+1:]:\n",
    "\n",
    "            if word2 in rhymes:\n",
    "                rhyme_pairs += 1\n",
    "\n",
    "    return rhyme_pairs\n",
    "\n",
    "df_mycs['rhyme_pairs'] = df_mycs['lyrics_cleaned'].apply(rhyme_count)\n",
    "\n",
    "# Preview the results\n",
    "print(\"First 5 rows with rhyme_pairs:\")\n",
    "print(df_mycs[['lyrics_cleaned', 'rhyme_pairs']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zRODOdrxzsvE",
    "outputId": "6e14873e-6d40-4b1e-d663-6bfebc16157e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows with rhyme_density:\n",
      "                                      lyrics_cleaned  rhyme_pairs  \\\n",
      "0  yeah ive been tryna call ive been on my own fo...           50   \n",
      "1   how do i get through one night without you if...           23   \n",
      "2  i do the same thing i told you that i never wo...           42   \n",
      "3  i do the same thing i told you that i never wo...           42   \n",
      "4  i dont want a lot for christmas there is just ...           42   \n",
      "\n",
      "   distinct_word_count  rhyme_density  \n",
      "0                   96       0.520833  \n",
      "1                   66       0.348485  \n",
      "2                   88       0.477273  \n",
      "3                   88       0.477273  \n",
      "4                  113       0.371681  \n"
     ]
    }
   ],
   "source": [
    "df_mycs['rhyme_density'] = df_mycs['rhyme_pairs'] / df_mycs['distinct_word_count']\n",
    "\n",
    "# Handle cases where distinct_word_count is 0 to avoid division-by-zero\n",
    "df_mycs['rhyme_density'] = df_mycs['rhyme_density'].fillna(0).replace([float('inf')], 0)\n",
    "\n",
    "# Preview the results\n",
    "print(\"First 5 rows with rhyme_density:\")\n",
    "print(df_mycs[['lyrics_cleaned', 'rhyme_pairs', 'distinct_word_count', 'rhyme_density']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6VkjyJB0mQf"
   },
   "source": [
    "Rhyme pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cYBh9_1G3qsA"
   },
   "source": [
    "TOPICS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OnL3SkiH5nBo"
   },
   "source": [
    "what words correlate most with mycs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3BdvhAvI3t03"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ybdrbUuja9-p",
    "outputId": "683c5ed9-0617-4765-d7c3-f54cdd4082df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['song', 'artist', 'year', 'ranking', 'MYCS', 'lyrics_cleaned',\n",
      "       'word_count', 'char_count', 'unique_word_count', 'unique_words',\n",
      "       'distinct_word_count', 'avg_word_length', 'stopword_ratio', 'pos_ratio',\n",
      "       'neg_ratio', 'neu_ratio', 'compound', 'lexical_diversity',\n",
      "       'syllable_count', 'rhyme_pairs', 'rhyme_density'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_mycs.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopword Repetition Ratio   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              song  word_count  stopword_count  \\\n",
      "0                  Blinding Lights         261             111   \n",
      "1                    how do i live         279             156   \n",
      "2                             Stay         423             199   \n",
      "3                             Stay         423             199   \n",
      "4  All I Want for Christmas Is You         391             186   \n",
      "\n",
      "   distinct_stopword_count  stopword_ratio  stopword_repetition_ratio  \n",
      "0                       32            0.43                       0.71  \n",
      "1                       21            0.56                       0.87  \n",
      "2                       30            0.47                       0.85  \n",
      "3                       30            0.47                       0.85  \n",
      "4                       29            0.48                       0.84  \n"
     ]
    }
   ],
   "source": [
    "# Count total stopwords\n",
    "df_mycs['stopword_count'] = df_mycs['lyrics_cleaned'].apply(\n",
    "    lambda x: sum(1 for word in x.split() if word.lower() in stop_words)\n",
    ")\n",
    "\n",
    "# Count distinct stopwords\n",
    "df_mycs['distinct_stopword_count'] = df_mycs['lyrics_cleaned'].apply(\n",
    "    lambda x: len(set(word.lower() for word in x.split() if word.lower() in stop_words))\n",
    ")\n",
    "\n",
    "# Calculate stopword repetition ratio\n",
    "df_mycs['stopword_repetition_ratio'] = df_mycs.apply(\n",
    "    lambda row: round(\n",
    "        1 - (row['distinct_stopword_count'] / row['stopword_count']),\n",
    "        2\n",
    "    ) if row['stopword_count'] > 0 else 0,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Preview results\n",
    "print(df_mycs[['song', 'word_count', 'stopword_count', 'distinct_stopword_count', 'stopword_ratio', 'stopword_repetition_ratio']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True Repitition Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              song  word_count  true_repetition_ratio\n",
      "0                  Blinding Lights         261                   0.84\n",
      "1                    how do i live         279                   0.90\n",
      "2                             Stay         423                   0.90\n",
      "3                             Stay         423                   0.90\n",
      "4  All I Want for Christmas Is You         391                   0.84\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def true_repetition_ratio(text):\n",
    "    words = text.split()\n",
    "    total = len(words)\n",
    "    if total == 0:\n",
    "        return 0\n",
    "    counts = Counter(words)\n",
    "    repeated_word_count = sum(count for word, count in counts.items() if count > 1)\n",
    "    return round(repeated_word_count / total, 2)\n",
    "\n",
    "df_mycs['true_repetition_ratio'] = df_mycs['lyrics_cleaned'].apply(true_repetition_ratio)\n",
    "\n",
    "# Preview results\n",
    "print(df_mycs[['song', 'word_count', 'true_repetition_ratio']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vocab Redundancy Ratio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              song  word_count  unique_word_count  \\\n",
      "0                  Blinding Lights         261                 43   \n",
      "1                    how do i live         279                 27   \n",
      "2                             Stay         423                 42   \n",
      "3                             Stay         423                 42   \n",
      "4  All I Want for Christmas Is You         391                 61   \n",
      "\n",
      "   vocab_redundancy_ratio  \n",
      "0                    0.84  \n",
      "1                    0.90  \n",
      "2                    0.90  \n",
      "3                    0.90  \n",
      "4                    0.84  \n"
     ]
    }
   ],
   "source": [
    "df_mycs['vocab_redundancy_ratio'] = df_mycs.apply(\n",
    "    lambda row: round(\n",
    "        1 - (row['unique_word_count'] / row['word_count']),\n",
    "        2\n",
    "    ) if row['word_count'] > 0 else 0,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Preview results\n",
    "print(df_mycs[['song', 'word_count', 'unique_word_count', 'vocab_redundancy_ratio']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line Breaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lyricsgenius in c:\\users\\zachr\\miniconda3\\lib\\site-packages (3.4.4)\n",
      "Requirement already satisfied: beautifulsoup4>=4.12.3 in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from lyricsgenius) (4.13.3)\n",
      "Requirement already satisfied: requests>=2.27.1 in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from lyricsgenius) (2.32.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from beautifulsoup4>=4.12.3->lyricsgenius) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from beautifulsoup4>=4.12.3->lyricsgenius) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from requests>=2.27.1->lyricsgenius) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from requests>=2.27.1->lyricsgenius) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from requests>=2.27.1->lyricsgenius) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from requests>=2.27.1->lyricsgenius) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "!pip install lyricsgenius "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for \"Blinding Lights\" by The Weeknd...\n",
      "Done.\n",
      "247 ContributorsTranslationsTürkçeSvenskaEspañolSlovenčinaРусскийPortuguêsPolskiNorsk (bokmål / riksmål)日本語ItalianoHebrewDeutschFrançaisفارسیNederlandsDanskShqipالعربيةСрпскиBlinding Lights Lyrics[Intro]\n",
      "Yeah\n",
      "\n",
      "[Verse 1]\n",
      "I've been tryna call\n",
      "I've been on my own for long enough\n",
      "Maybe you can show me how to love, maybe\n",
      "I'm goin' through withdrawals\n",
      "You don't even have to do too much\n",
      "You can turn me on with just a touch, baby\n",
      "\n",
      "[Pre-Chorus]\n",
      "I look around and\n",
      "Sin City's cold and empty (Oh)\n",
      "No one's around to judge me (Oh)\n",
      "I can't see clearly when you're gone\n",
      "\n",
      "[Chorus]\n",
      "I said, ooh, I'm blinded by the lights\n",
      "No, I can't sleep until I feel your touch\n",
      "I said, ooh, I'm drowning in the night\n",
      "Oh, when I'm like this, you're the one I trust\n",
      "Hey, hey, hey\n",
      "\n",
      "[Verse 2]\n",
      "I'm running out of time\n",
      "'Cause I can see the sun light up the sky\n",
      "So I hit the road in overdrive, baby, oh\n",
      "\n",
      "\n",
      "[Pre-Chorus]\n",
      "The city's cold and empty (Oh)\n",
      "No one's around to judge me (Oh)\n",
      "I can't see clearly when you're gone\n",
      "\n",
      "[Chorus]\n",
      "I said, ooh, I'm blinded by the lights\n",
      "No, I can't sleep until I feel your touch\n",
      "I said, ooh, I'm drowning in the night\n",
      "Oh, when I'm like this, you're the one I trust\n",
      "\n",
      "[Bridge]\n",
      "I'm just calling back to let you know (Back to let you know)\n",
      "I could never say it on the phone (Say it on the phone)\n",
      "Will never let you go this time (Ooh)\n",
      "\n",
      "[Chorus]\n",
      "I said, ooh, I'm blinded by the lights\n",
      "No, I can't sleep until I feel your touch\n",
      "Hey, hey, hey\n",
      "\n",
      "[Post-Chorus]\n",
      "Hey, hey, hey\n",
      "\n",
      "[Outro]\n",
      "I said, ooh, I'm blinded by the lights\n",
      "No, I can't sleep until I feel your touch\n"
     ]
    }
   ],
   "source": [
    "import lyricsgenius as genius\n",
    "\n",
    "api=genius.Genius('i5BgTB2QsuVYKN9SBeuNOQ5YkyzYtEEi_prbiJJwQPw689g9MDnJ3UcKJj5Ep2Mi')\n",
    "# artist = api.search_artist(\"Mariah Carey\", max_songs=3, sort=\"title\")\n",
    "# print(artist.songs)\n",
    "song = api.search_song(\"Blinding Lights\", \"The Weeknd\")\n",
    "print(song.lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\zachr\\miniconda3\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\zachr\\miniconda3\\lib\\site-packages (from scikit-learn) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1:\n",
      "im know just love youre dont time ill like got\n",
      "\n",
      "Topic 2:\n",
      "love oh baby dont im know want just like wanna\n",
      "\n",
      "Topic 3:\n",
      "yeah like im got aint know ooh dont bitch just\n",
      "\n",
      "Topic 4:\n",
      "la da que ah ha te doo yo lo wild\n",
      "\n",
      "Topic 5:\n",
      "na dont like got come im shake rock uh let\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Topic Modeling using LDA ---\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Vectorize lyrics\n",
    "vectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "dtm = vectorizer.fit_transform(df_mycs['lyrics_cleaned'])\n",
    "\n",
    "# Fit LDA model\n",
    "lda = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "lda.fit(dtm)\n",
    "\n",
    "# Display top words per topic\n",
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print(f\"Topic {idx + 1}:\")\n",
    "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "        print()\n",
    "\n",
    "display_topics(lda, vectorizer.get_feature_names_out(), 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b1afc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               song  pronoun_word_ratio  first_person_ratio  \\\n",
      "0                   Blinding Lights            0.145594            0.710526   \n",
      "1                     how do i live            0.261649            0.657534   \n",
      "2                              Stay            0.236407            0.610000   \n",
      "3                              Stay            0.236407            0.610000   \n",
      "4   All I Want for Christmas Is You            0.184143            0.652778   \n",
      "5                            Closer            0.204482            0.643836   \n",
      "6                        Heat Waves            0.133166            0.396226   \n",
      "7                         As It Was            0.108333            0.346154   \n",
      "8                            Closer            0.204482            0.643836   \n",
      "9                            smooth            0.140762            0.479167   \n",
      "10                       Bad Habits            0.139108            0.773585   \n",
      "11                you make me wanna            0.185639            0.462264   \n",
      "12                party rock anthem            0.110849            0.361702   \n",
      "13                     shake it off            0.132692            0.898551   \n",
      "14                   Girls Like You            0.179028            0.571429   \n",
      "15                   Girls Like You            0.172414            0.600000   \n",
      "16                  i gotta feeling            0.042781            0.875000   \n",
      "17             just the way you are            0.200717            0.339286   \n",
      "18                         im yours            0.139344            0.607843   \n",
      "19                gangstas paradise            0.165323            0.670732   \n",
      "20                           royals            0.115702            0.738095   \n",
      "21              all about that bass            0.076233            0.352941   \n",
      "22                         Good 4 U            0.184915            0.434211   \n",
      "23                Someone You Loved            0.155963            0.686275   \n",
      "24                        You Proof            0.126923            0.696970   \n",
      "25                    Industry Baby            0.154362            0.565217   \n",
      "26                      gold digger            0.140867            0.274725   \n",
      "27                    Industry Baby            0.154362            0.565217   \n",
      "28                       wake me up            0.159184            0.948718   \n",
      "29                  Save Your Tears            0.243542            0.530303   \n",
      "30                  Save Your Tears            0.042463            0.400000   \n",
      "31                       Levitating            0.214418            0.655172   \n",
      "32               whoomp there it is            0.068337            0.566667   \n",
      "33                moves like jagger            0.124365            0.551020   \n",
      "34                       Better Now            0.213861            0.361111   \n",
      "35                    family affair            0.101695            0.500000   \n",
      "36                          Bad Guy            0.139535            0.416667   \n",
      "37                             Mood            0.157248            0.515625   \n",
      "38               how to save a life            0.157480            0.416667   \n",
      "39                             Mood            0.157248            0.515625   \n",
      "40                       Sicko Mode            0.105402            0.712500   \n",
      "41                           I Hope            0.044118            0.777778   \n",
      "42          Something in the Orange            0.177606            0.630435   \n",
      "43                           I Hope            0.222698            0.413462   \n",
      "44             ill make love to you            0.227891            0.388060   \n",
      "45                         dynamite            0.148760            0.870370   \n",
      "46                   live your life            0.122748            0.577982   \n",
      "47                whatever you like            0.197767            0.290323   \n",
      "48                          fantasy            0.155797            0.651163   \n",
      "49                   one more night            0.195599            0.650000   \n",
      "\n",
      "    second_person_ratio  third_person_ratio  male_pronoun_ratio  \\\n",
      "0              0.289474            0.000000            0.000000   \n",
      "1              0.342466            0.000000            0.000000   \n",
      "2              0.390000            0.000000            0.000000   \n",
      "3              0.390000            0.000000            0.000000   \n",
      "4              0.347222            0.000000            0.000000   \n",
      "5              0.328767            0.027397            0.000000   \n",
      "6              0.603774            0.000000            0.000000   \n",
      "7              0.576923            0.076923            0.038462   \n",
      "8              0.328767            0.027397            0.000000   \n",
      "9              0.520833            0.000000            0.000000   \n",
      "10             0.226415            0.000000            0.000000   \n",
      "11             0.500000            0.037736            0.000000   \n",
      "12             0.617021            0.021277            0.000000   \n",
      "13             0.028986            0.072464            0.014493   \n",
      "14             0.428571            0.000000            0.000000   \n",
      "15             0.400000            0.000000            0.000000   \n",
      "16             0.041667            0.083333            0.000000   \n",
      "17             0.375000            0.285714            0.000000   \n",
      "18             0.392157            0.000000            0.000000   \n",
      "19             0.109756            0.219512            0.000000   \n",
      "20             0.261905            0.000000            0.000000   \n",
      "21             0.441176            0.205882            0.000000   \n",
      "22             0.552632            0.013158            0.000000   \n",
      "23             0.313725            0.000000            0.000000   \n",
      "24             0.242424            0.060606            0.000000   \n",
      "25             0.228261            0.206522            0.086957   \n",
      "26             0.175824            0.549451            0.186813   \n",
      "27             0.228261            0.206522            0.086957   \n",
      "28             0.000000            0.051282            0.000000   \n",
      "29             0.469697            0.000000            0.000000   \n",
      "30             0.400000            0.200000            0.050000   \n",
      "31             0.344828            0.000000            0.000000   \n",
      "32             0.433333            0.000000            0.000000   \n",
      "33             0.387755            0.061224            0.000000   \n",
      "34             0.620370            0.018519            0.018519   \n",
      "35             0.500000            0.000000            0.000000   \n",
      "36             0.500000            0.083333            0.000000   \n",
      "37             0.484375            0.000000            0.000000   \n",
      "38             0.366667            0.216667            0.216667   \n",
      "39             0.484375            0.000000            0.000000   \n",
      "40             0.062500            0.225000            0.075000   \n",
      "41             0.222222            0.000000            0.000000   \n",
      "42             0.369565            0.000000            0.000000   \n",
      "43             0.384615            0.201923            0.009615   \n",
      "44             0.611940            0.000000            0.000000   \n",
      "45             0.129630            0.000000            0.000000   \n",
      "46             0.311927            0.110092            0.000000   \n",
      "47             0.653226            0.056452            0.000000   \n",
      "48             0.325581            0.023256            0.000000   \n",
      "49             0.350000            0.000000            0.000000   \n",
      "\n",
      "    female_pronoun_ratio  \n",
      "0               0.000000  \n",
      "1               0.000000  \n",
      "2               0.000000  \n",
      "3               0.000000  \n",
      "4               0.000000  \n",
      "5               0.000000  \n",
      "6               0.000000  \n",
      "7               0.038462  \n",
      "8               0.000000  \n",
      "9               0.000000  \n",
      "10              0.000000  \n",
      "11              0.037736  \n",
      "12              0.021277  \n",
      "13              0.000000  \n",
      "14              0.000000  \n",
      "15              0.000000  \n",
      "16              0.083333  \n",
      "17              0.267857  \n",
      "18              0.000000  \n",
      "19              0.000000  \n",
      "20              0.000000  \n",
      "21              0.117647  \n",
      "22              0.013158  \n",
      "23              0.000000  \n",
      "24              0.000000  \n",
      "25              0.032609  \n",
      "26              0.307692  \n",
      "27              0.032609  \n",
      "28              0.000000  \n",
      "29              0.000000  \n",
      "30              0.100000  \n",
      "31              0.000000  \n",
      "32              0.000000  \n",
      "33              0.000000  \n",
      "34              0.000000  \n",
      "35              0.000000  \n",
      "36              0.083333  \n",
      "37              0.000000  \n",
      "38              0.000000  \n",
      "39              0.000000  \n",
      "40              0.100000  \n",
      "41              0.000000  \n",
      "42              0.000000  \n",
      "43              0.192308  \n",
      "44              0.000000  \n",
      "45              0.000000  \n",
      "46              0.000000  \n",
      "47              0.024194  \n",
      "48              0.023256  \n",
      "49              0.000000  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Updated pronoun lists with contractions\n",
    "first_person = [\n",
    "    \"i\", \"me\", \"my\", \"mine\", \"we\", \"us\", \"our\", \"ours\",\n",
    "    \"i'm\", \"i've\", \"i'd\", \"i'll\", \"we're\", \"we've\", \"we'd\", \"we'll\"\n",
    "]\n",
    "second_person = [\n",
    "    \"you\", \"your\", \"yours\", \"u\",\n",
    "    \"you're\", \"you've\", \"you'd\", \"you'll\"\n",
    "]\n",
    "third_person = [\n",
    "    \"he\", \"him\", \"his\", \"she\", \"her\", \"hers\", \"they\", \"them\", \"their\", \"theirs\",\n",
    "    \"he's\", \"he'd\", \"he'll\", \"she's\", \"she'd\", \"she'll\",\n",
    "    \"they're\", \"they've\", \"they'd\", \"they'll\"\n",
    "]\n",
    "male_pronouns = [\"he\", \"him\", \"his\", \"he's\", \"he'd\", \"he'll\"]\n",
    "female_pronouns = [\"she\", \"her\", \"hers\", \"she's\", \"she'd\", \"she'll\"]\n",
    "gender_neutral_pronouns = [\"they\", \"they're\", \"they've\", \"they'd\", \"they'll\", \"them\", \"their\", \"theirs\", \"themself\", \"themselves\"]\n",
    "\n",
    "\n",
    "def count_pronouns(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"[^\\w\\s']\", \"\", text)  # keep apostrophes for contractions\n",
    "    words = text.split()\n",
    "\n",
    "    fp = sum(word in first_person for word in words)\n",
    "    sp = sum(word in second_person for word in words)\n",
    "    tp = sum(word in third_person for word in words)\n",
    "    male = sum(word in male_pronouns for word in words)\n",
    "    female = sum(word in female_pronouns for word in words)\n",
    "    total = fp + sp + tp\n",
    "\n",
    "    return pd.Series({\n",
    "        \"first_person\": fp,\n",
    "        \"second_person\": sp,\n",
    "        \"third_person\": tp,\n",
    "        \"male_pronouns\": male,\n",
    "        \"female_pronouns\": female,\n",
    "        \"total_pronouns\": total\n",
    "    })\n",
    "\n",
    "# Apply to your lyrics\n",
    "pronoun_features = df_mycs[\"lyrics_cleaned\"].apply(count_pronouns)\n",
    "df_mycs = pd.concat([df_mycs, pronoun_features], axis=1)\n",
    "df_mycs = df_mycs.loc[:, ~df_mycs.columns.duplicated()]  # just in case\n",
    "\n",
    "# Compute ratios safely\n",
    "df_mycs[\"pronoun_word_ratio\"] = df_mycs[\"total_pronouns\"] / df_mycs[\"word_count\"].replace(0, 1)\n",
    "df_mycs[\"first_person_ratio\"] = df_mycs[\"first_person\"] / df_mycs[\"total_pronouns\"].replace(0, 1)\n",
    "df_mycs[\"second_person_ratio\"] = df_mycs[\"second_person\"] / df_mycs[\"total_pronouns\"].replace(0, 1)\n",
    "df_mycs[\"third_person_ratio\"] = df_mycs[\"third_person\"] / df_mycs[\"total_pronouns\"].replace(0, 1)\n",
    "df_mycs[\"male_pronoun_ratio\"] = df_mycs[\"male_pronouns\"] / df_mycs[\"total_pronouns\"].replace(0, 1)\n",
    "df_mycs[\"female_pronoun_ratio\"] = df_mycs[\"female_pronouns\"] / df_mycs[\"total_pronouns\"].replace(0, 1)\n",
    "\n",
    "# Preview the results\n",
    "print(df_mycs[[\n",
    "    \"song\", \"pronoun_word_ratio\", \"first_person_ratio\", \"second_person_ratio\",\n",
    "    \"third_person_ratio\", \"male_pronoun_ratio\", \"female_pronoun_ratio\"\n",
    "]].head())\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
